TODO, LLM chatbot
    ChatGPT was able to provide a good roadmap for working from simple to more complex; With the caveat of at each step of abstraction, I want to make use of popular and powerful tools to complete a project or challenge(s) that would contribute to my understanding, as well as make a "minimal viable project" (MVP) at each step.

    Where the roadmap is focused on developing expertise in neural networks (NN), then natural language processing (NLP), deep learning, transformer models, creating a progressively more complex chat bot, making a polished interface, and finishing with deployment and scaling.

    Roadmap
        Step-by-Step Roadmap (Revised)
            Basic Neural Network Implementation

            Objective: Understand the fundamentals of neural networks.
            Project: Implement a simple feedforward neural network from scratch.
            Skills Learned: Backpropagation, gradient descent, activation functions.
            Technologies: Pure Python, NumPy.
            Using a Deep Learning Framework

            Objective: Get familiar with a popular deep learning framework.
            Project: Re-implement the basic neural network using PyTorch or TensorFlow.
            Skills Learned: Using tensors, automatic differentiation, basic model training.
            Technologies: PyTorch, TensorFlow.
            Text Data Preprocessing

            Objective: Learn how to preprocess text data for NLP tasks.
            Project: Implement text preprocessing techniques such as tokenization, stemming, lemmatization, and stop words removal.
            Skills Learned: Text normalization, handling different text formats.
            Technologies: NLTK, SpaCy.
            Word Embeddings and Text Representation

            Objective: Understand how to represent text data in a way that neural networks can process.
            Project: Implement and use word embeddings like Word2Vec or GloVe for text representation.
            Skills Learned: Embedding layers, vector space models.
            Technologies: Gensim, PyTorch, TensorFlow.
            Recurrent Neural Networks (RNNs) and LSTMs

            Objective: Learn about RNNs for handling sequential data.
            Project: Build an RNN or LSTM for a simple text generation task.
            Skills Learned: Handling sequences, managing hidden states, text generation.
            Technologies: PyTorch, TensorFlow.
            Transformer Models

            Objective: Dive into the architecture behind modern LLMs.
            Project: Implement a simple transformer model for a text-based task, such as translation or summarization.
            Skills Learned: Attention mechanisms, positional encoding, multi-head attention.
            Technologies: PyTorch, TensorFlow, Hugging Face Transformers.
            Fine-Tuning Pre-Trained Models

            Objective: Leverage pre-trained models for specific NLP tasks.
            Project: Fine-tune a pre-trained BERT or GPT model for a custom text classification task.
            Skills Learned: Transfer learning, fine-tuning, handling large-scale pre-trained models.
            Technologies: Hugging Face Transformers, PyTorch, TensorFlow.
            Building a Basic Chatbot

            Objective: Create an interactive chatbot with basic conversational capabilities.
            Project: Develop a simple rule-based chatbot to handle predefined interactions.
            Skills Learned: Basic NLP techniques, intent recognition, response generation.
            Technologies: NLTK, Rasa, Python.
            Developing a Context-Aware Chatbot

            Objective: Enhance the chatbot with context management for more natural conversations.
            Project: Implement a context-aware chatbot using an LSTM or Transformer-based model.
            Skills Learned: Context tracking, managing stateful interactions.
            Technologies: Rasa, PyTorch, TensorFlow.
            Integrating a Pre-Trained LLM into the Chatbot

            Objective: Leverage a pre-trained LLM for sophisticated responses.
            Project: Integrate GPT-3 (via OpenAI API) or another LLM into your chatbot for more advanced conversations.
            Skills Learned: API integration, managing API limitations, ensuring coherent responses.
            Technologies: OpenAI API, Hugging Face Transformers, Flask/Django for web integration.
            Polishing the User Interface

            Objective: Make the chatbot user-friendly and visually appealing.
            Project: Develop a web or mobile interface for your chatbot.
            Skills Learned: Front-end development, integrating back-end AI models with the UI.
            Technologies: React.js, Vue.js, HTML/CSS, Flask/Django, RESTful APIs.
            Deployment and Scaling

            Objective: Deploy the chatbot and ensure it can handle multiple users.
            Project: Deploy your chatbot on a cloud platform, ensure it is scalable and reliable.
            Skills Learned: Cloud deployment, containerization (Docker), orchestration (Kubernetes).
            Technologies: AWS/GCP/Azure, Docker, Kubernetes.
    
    --

    TODO, LLM chat bot, step 1, Basic Neural Network Implementation
        Basic Neural Network Implementation

        Objective: Understand the fundamentals of neural networks.
        Project: Implement a simple feedforward neural network from scratch.
        Skills Learned: Backpropagation, gradient descent, activation functions.
        Technologies: Pure Python, NumPy.

        --

        This seems easier to manage on github
            see:
            https://github.com/pjmattingly/1-Basic-Neural-Network-Implementation/tree/main

        --

        Then drilling down to the first step.
            see:
            https://github.com/pjmattingly/1-Basic-Neural-Network-Implementation/tree/main/1-Initialize-the-Network

        And setting up a plan for the code.
            see:
            https://github.com/pjmattingly/1-Basic-Neural-Network-Implementation/blob/main/1-Initialize-the-Network/Code_Structure.md

        Then the local repo
            see:
            D:\Github\1-Basic-Neural-Network-Implementation

            and:
            D:\Github\1-Basic-Neural-Network-Implementation\1-Initialize-the-Network

        --

        [06.29.24]

        --

        what sort of resources can I reference for starting development?
            books, courses, etc.

            --

            recommendations
                To get started on the "Basic Neural Network Implementation" step, it's beneficial to have a solid understanding of the underlying theory. Here are some recommended resources that cover the essential theoretical background:

                ### Books

                1. **"Deep Learning" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville**
                - Comprehensive introduction to the fundamentals of deep learning, including neural networks, backpropagation, and various architectures.

                2. **"Neural Networks and Deep Learning" by Michael Nielsen**
                - Free online book that provides a clear and intuitive introduction to the principles of neural networks and deep learning.

                3. **"Pattern Recognition and Machine Learning" by Christopher Bishop**
                - Covers a broad range of machine learning topics, including neural networks, from a probabilistic perspective.

                ### Online Courses

                1. **Coursera: Deep Learning Specialization by Andrew Ng (deeplearning.ai)**
                - Series of courses covering neural networks, deep learning, and related topics. Highly recommended for a structured learning path.

                2. **edX: Machine Learning with Python: from Linear Models to Deep Learning by MIT**
                - Comprehensive course that covers the fundamentals of machine learning and deep learning.

                3. **Udacity: Deep Learning Nanodegree**
                - In-depth program focused on neural networks and deep learning, including practical projects.

                ### Tutorials and Articles

                1. **3Blue1Brown: Neural Networks (YouTube Series)**
                - Visual and intuitive explanations of neural networks and backpropagation.

                2. **Khan Academy: Neural Networks**
                - Introduction to the basics of neural networks with interactive visualizations.

                3. **Towards Data Science (Medium): Various Articles on Neural Networks**
                - Platform with numerous articles explaining different aspects of neural networks and deep learning.

                ### Research Papers

                1. **"Gradient-Based Learning Applied to Document Recognition" by Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner**
                - Seminal paper on convolutional neural networks, providing insights into early neural network research.

                2. **"Efficient BackProp" by Yann LeCun, Léon Bottou, Genevieve B. Orr, and Klaus-Robert Müller**
                - Detailed explanation of backpropagation and its optimization.

                ### Documentation and Libraries

                1. **NumPy Documentation**
                - Essential for understanding how to perform mathematical operations efficiently in Python.

                2. **TensorFlow and PyTorch Documentation**
                - Useful for understanding how to implement neural networks using popular deep learning frameworks.

                ### Summary

                By utilizing these resources, you'll gain a thorough understanding of the theory behind neural networks, which will be invaluable as you implement your own basic neural network from scratch. This foundational knowledge will also help you tackle more advanced topics and projects in the future

            --

            Then reviewing book recommendations
                Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT press.

                --

                well cited
                positive reviews
                I actually purchased it one point
                    see:
                    https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Deep+Learning+Ian+Goodfellow&btnG=

                    and:
                    https://www.reddit.com/r/MachineLearning/comments/4dt4gt/deep_learning_book_by_ian_goodfellow_yoshua/

                    and:
                    https://www.amazon.ca/Deep-Learning-Ian-Goodfellow/dp/0262035618

                    and:
                    https://books.google.ca/books/about/Deep_Learning.html?id=-s2MEAAAQBAJ&source=kp_book_description&redir_esc=y

                And so seems like a good resource moving forward
        DONE
            Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT press.

            This seems like a good fit.
                see:
                C:\Users\peter-work\Calibre Library\Goodfellow, Ian; Bengio, Yoshua; Cou\Deep Learning (19)\Deep Learning - Goodfellow, Ian; Bengio, Yoshua.pdf
        
        --

        is there a good method for integrating development and research notes in association with the code?
            It would be nice to keep such notes in the repo itself instead of separately
        DONE
            a markdown file in the repo should be fine

        --

        also, this might be a good place to take a closer look at modern software development practices, so I can implement them here
            Agile seems like overkill, but it might be nice to have a simpler and more modern method for development.
        DONE
            my standard approach of iterative development coupled with Test Driven Development seems fine

        --

        maybe try out asking for code review from ChatGPT in between implementing major features?
            asking about its capabilities
                ChatGPT has several capabilities that can be highly useful for code review. While it cannot execute or test the code directly, it can analyze and provide feedback based on the code provided to it. Here’s how ChatGPT can assist with code review:

                ### Capabilities

                1. **Syntax and Style Checking:**
                - **Syntax Issues:** Identify and point out syntax errors or inconsistencies in the code.
                - **Coding Standards:** Provide feedback on adherence to coding standards and best practices (e.g., PEP 8 for Python).

                2. **Logical and Structural Analysis:**
                - **Logic Flaws:** Highlight potential logical errors or areas where the logic might not produce the intended results.
                - **Structure and Organization:** Suggest improvements in code organization and structure for better readability and maintainability.

                3. **Efficiency and Optimization:**
                - **Performance:** Identify potential performance bottlenecks and suggest optimizations.
                - **Algorithm Efficiency:** Provide feedback on the efficiency of algorithms used and suggest more optimal approaches if applicable.

                4. **Documentation and Comments:**
                - **Docstrings and Comments:** Review and suggest improvements for in-code documentation and comments.
                - **Clarity:** Ensure that the code is well-documented and that comments enhance understanding without being redundant.

                5. **Security Considerations:**
                - **Vulnerabilities:** Point out potential security vulnerabilities in the code.
                - **Best Practices:** Suggest security best practices to follow (e.g., input validation, avoiding hard-coded credentials).

                6. **Code Readability:**
                - **Naming Conventions:** Suggest improvements to variable, function, and class names for better clarity.
                - **Code Clarity:** Provide feedback on making the code more readable and maintainable by suggesting better structuring or refactoring.

                ### Example Code Review Process with ChatGPT

                1. **Submit Code for Review:**
                - Provide a snippet or full block of code that you want reviewed.

                2. **Identify Issues and Suggestions:**
                - ChatGPT will analyze the code and identify potential issues, offering suggestions for improvements. This might include syntax errors, logic flaws, or inefficiencies.

                3. **Request Specific Feedback:**
                - You can ask for feedback on specific aspects of the code, such as algorithm efficiency, security practices, or adherence to coding standards.

                4. **Iterative Feedback:**
                - Make changes based on the feedback and resubmit the code for further review. This iterative process can help refine and improve the code quality.

                ### Limitations

                While ChatGPT is powerful, it does have limitations:
                - **Context Awareness:** ChatGPT may not have full context if only a part of the codebase is provided, potentially missing dependencies or interactions with other parts of the code.
                - **Dynamic Analysis:** It cannot run the code, so it relies on static analysis and cannot identify runtime issues.
                - **Specific Language Nuances:** While ChatGPT supports many programming languages, there may be nuances in certain languages or frameworks that it might not fully capture.

                ### Practical Example

                Suppose you provide the following Python code snippet for review:

                ```python
                def calculate_sum(numbers):
                    result = 0
                    for num in numbers:
                        result += num
                    return result

                numbers = [1, 2, 3, 4, 5]
                print(calculate_sum(numbers))
                ```

                **ChatGPT’s Review:**

                1. **Correctness:**
                - The function `calculate_sum` correctly sums up the elements of the list `numbers`.

                2. **Optimization:**
                - The function can be optimized using Python’s built-in `sum()` function for better readability and performance.
                - Suggested Improvement: `return sum(numbers)`

                3. **Documentation:**
                - Adding a docstring to the function improves readability and maintainability.
                - Suggested Improvement:
                    ```python
                    def calculate_sum(numbers):
                        """
                        Calculate the sum of a list of numbers.
                        
                        Parameters:
                        numbers (list): A list of numeric values.
                        
                        Returns:
                        int: The sum of the numbers in the list.
                        """
                        return sum(numbers)
                    ```

                4. **Variable Naming:**
                - The variable names are clear, but consider renaming `result` to something more descriptive if the function were more complex.

                By following these suggestions, the revised code might look like:

                ```python
                def calculate_sum(numbers):
                    """
                    Calculate the sum of a list of numbers.
                    
                    Parameters:
                    numbers (list): A list of numeric values.
                    
                    Returns:
                    int: The sum of the numbers in the list.
                    """
                    return sum(numbers)

                numbers = [1, 2, 3, 4, 5]
                print(calculate_sum(numbers))
                ```

                ### Conclusion

                ChatGPT can provide valuable insights and suggestions for improving code through static analysis. By leveraging its capabilities, you can enhance code quality, readability, and maintainability, ultimately leading to better software development practices. However, it’s important to complement this with dynamic testing and real-world usage to ensure comprehensive code quality.

            --

            and so it seems best to ask for code review for specific, self-contained blocks of code

            it's not clear how it would handle me submitting my entire code-base and asking for feedback on specific parts, and so seems worth testing.

        --

        Then given the test-centric approach, what test-framework would be useful to work with?
            discussion
                When developing a neural network project in Python, it's crucial to use a robust testing framework to ensure the correctness and reliability of your code. Here are some popular and reasonable test frameworks for Python, along with their features and use cases:

                ### 1. **unittest**
                - **Description:** The built-in Python testing framework, also known as `PyUnit`.
                - **Features:**
                - Comes with Python’s standard library, no additional installation required.
                - Supports test discovery, test fixtures, and test suites.
                - Integrates well with many continuous integration tools.
                - **Use Cases:** Suitable for unit testing small to medium-sized projects where you need to write simple test cases.
                - **Example:**
                ```python
                import unittest

                class TestNeuron(unittest.TestCase):
                    def test_forward_pass(self):
                        neuron = Neuron(3)  # assuming a Neuron class is defined
                        output = neuron.forward([1.0, 2.0, 3.0])
                        self.assertIsNotNone(output)

                if __name__ == '__main__':
                    unittest.main()
                ```

                ### 2. **pytest**
                - **Description:** A more powerful and flexible testing framework that supports fixtures, parameterized testing, and plugins.
                - **Features:**
                - Simple syntax, making it easy to write concise test cases.
                - Extensive plugin architecture (e.g., pytest-cov for coverage).
                - Detailed assertion introspection, showing useful information when tests fail.
                - Support for test discovery.
                - **Use Cases:** Ideal for both small and large projects, especially when you need advanced features like fixtures and parameterized tests.
                - **Example:**
                ```python
                def test_forward_pass():
                    neuron = Neuron(3)
                    output = neuron.forward([1.0, 2.0, 3.0])
                    assert output is not None
                ```

                ### 3. **doctest**
                - **Description:** Tests embedded in docstrings that verify that interactive examples in docstrings produce the expected results.
                - **Features:**
                - Allows you to test code examples in documentation.
                - Simple to set up and use.
                - **Use Cases:** Useful for ensuring that code examples in your documentation remain correct.
                - **Example:**
                ```python
                def add(a, b):
                    """
                    Adds two numbers.

                    >>> add(2, 3)
                    5
                    >>> add('a', 'b')
                    'ab'
                    """
                    return a + b

                if __name__ == "__main__":
                    import doctest
                    doctest.testmod()
                ```

                ### 4. **nose2**
                - **Description:** Successor to the `nose` framework, designed to extend unittest to make testing easier.
                - **Features:**
                - Extends unittest with additional features like test discovery and plugins.
                - Compatible with unittest tests.
                - **Use Cases:** Useful if you need unittest compatibility with additional features.
                - **Example:**
                ```python
                import unittest

                class TestNeuron(unittest.TestCase):
                    def test_forward_pass(self):
                        neuron = Neuron(3)
                        output = neuron.forward([1.0, 2.0, 3.0])
                        self.assertIsNotNone(output)

                if __name__ == '__main__':
                    unittest.main()
                ```

                ### 5. **Hypothesis**
                - **Description:** A property-based testing library that generates test cases for you.
                - **Features:**
                - Automatically generates a wide range of input data to test edge cases.
                - Integrates with pytest for more comprehensive testing.
                - **Use Cases:** Ideal for testing functions with complex input spaces where edge cases might be overlooked.
                - **Example:**
                ```python
                from hypothesis import given
                from hypothesis.strategies import lists, floats

                @given(lists(floats(min_value=0, max_value=1), min_size=3, max_size=3))
                def test_forward_pass(inputs):
                    neuron = Neuron(3)
                    output = neuron.forward(inputs)
                    assert output is not None
                ```

                ### Conclusion

                For a neural network project in Python, using a combination of these frameworks can be beneficial:

                - **unittest** or **pytest** for general unit testing and integration tests.
                - **doctest** for verifying code examples in documentation.
                - **Hypothesis** for property-based testing to ensure robustness against a wide range of inputs.

                Among these, **pytest** is highly recommended due to its simplicity, flexibility, and powerful features, making it suitable for projects of all sizes.
        DONE
            pytest looks good
                see:
                https://docs.pytest.org/en/8.2.x/

        --

        Then, since we need numpy and pytest for the project, what sort of package management would be useful?
        DONE
            poetry looks good
                see:
                https://python-poetry.org/
        
        --

        then doing initial setup before starting coding
            TODO file tracking
                see:
                https://github.com/pjmattingly/1-Basic-Neural-Network-Implementation/blob/main/TODO%2C%20LLM%20chatbot.txt

            Install Poetry
                they recommend using pipx
                    see:
                    https://python-poetry.org/docs/

                then pipx recommends using "scoop" to install
                    see:
                    https://pipx.pypa.io/stable/installation/

                then scoop is another package manager like chocolatey
                    see:
                    https://scoop.sh/

                    and:
                    https://en.wikipedia.org/wiki/Chocolatey

                    and:
                    https://en.wikipedia.org/wiki/Scoop_Package_Manager

                then, since there's a new package manager, what sort of shell should I be using for development?
                    see:
                    https://www.reddit.com/r/learnprogramming/comments/zbssou/good_terminals_for_windows/

                    and:
                    https://www.reddit.com/r/learnprogramming/comments/1ag3g86/what_do_developers_using_windows_use_as_shell/

                    and:
                    https://en.wikipedia.org/wiki/Windows_Terminal
                DONE
                    then consensus seems to be Windows Terminal, instead of the venerable cmder

                and Windows Terminal installed scoop without a hitch, and seems to have standard Linux commands, and tab completion
            DONE

            then, getting Windows Terminal to recognize git
            DONE
                see:
                https://dev.to/yuta28/customize-windows-terminal-and-git-operations-4el2

            --

            [06.30.24]

            --

            setting up numpy and pytest in "1-Initialize-the-Network"
            DONE
                see:
                https://python-poetry.org/docs/basic-usage/

            --

            TODO, before development, review: "Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT press."
                first, checking on the structure of artificial neurons; Why are they structured the way they are?
                    "Some of the earliest learning algorithms we recognize today were intended
                    to be computational models of biological learning, that is, models of how
                    learning happens or could happen in the brain."

                    "As a result, one of the names
                    that deep learning has gone by is artificial neural networks (ANNs)."

                    "While the kinds of neural networks used for machine
                    learning have sometimes been used to understand brain function (Hinton and
                    Shallice, 1991), they are generally not designed to be realistic models of
                    biological function."

                    "multiple levels of composition" ?
                        "e modern term “deep learning” goes beyond the neuroscientific
                        perspective on the current breed of machine learning models. It appeals to a
                        more general principle of learning multiple levels of composition, which can be
                        applied in machine learning frameworks that are not necessarily neurally
                        inspired."

                    --

                    "e training algorithm used to adapt the weights of the
                    ADALINE was a special case of an algorithm called stochastic gradient
                    descent."

                    "Slightly modified versions of the stochastic gradient descent algorithm
                    remain the dominant training algorithms for deep learning models today."

                    --

                    "Most neural networks today are based
                    on a model neuron called the rectified linear unit."

                    "e simplified modern version
                    was developed incorporating ideas from many viewpoints, with Nair and
                    Hinton (2010) and Glorot et al. (2011a) citing neuroscience as an influence,
                    and Jarrett et al. (2009) citing more engineering-oriented influences"

                    and so modern logical neurons are "evolved" from earlier more complex representations, as they seem to be the simplest logical constructs that perform well at the kinds of tasks associated with machine learning
                        "We know that actual neurons compute very different functions
                        than modern rectified linear units, but greater neural realism has not yet led to
                        an improvement in machine learning performance."

                    --

                    "Another major accomplishment of the connectionist movement was the
                    successful use of back-propagation to train deep neural networks with internal
                    representations and the popularization of the back-propagation algorithm
                    (Rumelhart et al., 1986a; LeCun, 1987)."

                    --

                    " Hochreiter and Schmidhuber (1997)
                    introduced the long short-term memory (LSTM) network to resolve some of
                    these difficulties."

                    "Today, the LSTM is widely used for many sequence modeling
                    tasks, including many natural language processing tasks at Google."

                    --

                    "At this time, deep neural networks outperformed competing AI
                    systems based on other machine learning technologies as well as hand-designed
                    functionality."

                    "e third wave began with a focus
                    on new unsupervised learning techniques and the ability of deep models to
                    generalize well from small datasets, but today there is more interest in much
                    older supervised learning algorithms and the ability of deep models to leverage
                    large labeled datasets."

                    ----

                    "Another crowning achievement of deep learning is its extension to the
                    domain of reinforcement learning."

                    "In the context of reinforcement learning,
                    an autonomous agent must learn to perform a task by trial and error, without
                    any guidance from the human operator."

                    ----

                    "By adding more layers and more units within a layer, a deep network
                    can represent functions of increasing complexity"

                    "Most tasks that consist of
                    mapping an input vector to an output vector, and that are easy for a person to
                    do rapidly, can be accomplished via deep learning, given sufficiently large
                    models and sufficiently large datasets of labeled training examples"

                    ----

                    "Deep feedforward networks, also called feedforward neural networks, or
                    multilayer perceptrons (MLPs), are the quintessential deep learning models."

                    "e goal of a feedforward network is to approximate some function f*. For
                    example, for a classifier, y = f*(x) maps an input x to a category y. A feedforward
                    network defines a mapping y = f(x;
                    θ) and learns the value of the parameters
                    θ
                    that result in the best function approximation."

                    --

                    "ese models are called feedforward because information flows through the
                    function being evaluated from x, through the intermediate computations used
                    to define f, and finally to the output y."

                    "ere are no feedback connections in
                    which outputs of the model are fed back into itself."

                    --

                    "Feedforward neural networks are called networks because they are typically
                    represented by composing together many different functions. e model is
                    associated with a directed acyclic graph describing how the functions are
                    composed together. For example, we might have three functions f(1), f(2), and
                    f(3) connected in a chain, to form f(x) = f(3)(f(2)(f(1)(x))). ese chain
                    structures are the most commonly used structures of neural networks"

                    " In this
                    case, f(1) is called the first layer of the network, f(2) is called the second layer,
                    and so on. e overall length of the chain gives the depth of the model."

                    "e final layer of a
                    feedforward network is called the output layer."

                    --

                    "During neural network
                    training, we drive f(x) to match f*(x). e training data provides us with noisy,
                    approximate examples of f*(x) evaluated at different training points."

                    "e learning algorithm must decide how to use those layers to
                    produce the desired output, but the training data do not say what each
                    individual layer should do."

                    "Instead, the learning algorithm must decide how to
                    use these layers to best implement an approximation of f*."

                    "Because the training
                    data does not show the desired output for each of these layers, they are called
                    hidden layers."

                    --

                    "Finally, these networks are called neural because they are loosely inspired by
                    neuroscience. Each hidden layer of the network is typically vector valued. e
                    dimensionality of these hidden layers determines the width of the model. Each
                    element of the vector may be interpreted as playing a role analogous to a
                    neuron"

                    "Rather than thinking of the layer as representing a single vector-to-
                    vector function, we can also think of the layer as consisting of many units that
                    act in parallel, each representing a vector-to-scalar function."

                    "Each unit
                    resembles a neuron in the sense that it receives input from many other units and
                    computes its own activation value."

                    "e choice of the functions
                    f(i)(x) used to compute these representations is also loosely guided by
                    neuroscientific observations about the functions that biological neurons
                    compute."

                    --

                    "It is best to think of feedforward networks as
                    function approximation machines that are designed to achieve statistical
                    generalization, occasionally drawing some insights from what we know about
                    the brain, rather than as models of brain function."

                    --

                    "To extend linear models to represent nonlinear functions of x, we can apply
                    the linear model not to x itself but to a transformed input
                    ϕ(x), where
                    ϕ is a
                    nonlinear transformation."

                    e strategy of deep learning is to learn
                    ϕ

                    "In this approach, we have
                    a model y = f(x;
                    θ, w) =
                    ϕ(x;
                    θ)⊤w. We now have parameters
                    θ that
                    we use to learn
                    ϕ from a broad class of functions, and parameters w
                    that map from
                    ϕ(x) to the desired output."

                    "is is an example of a
                    deep feedforward network, with
                    ϕ defining a hidden layer."

                    " In this
                    approach, we parametrize the representation as
                    ϕ(x;
                    θ) and use the
                    optimization algorithm to find the
                    θ that corresponds to a good
                    representation"

                    " If we wish, this approach can capture the benefit of
                    the first approach by being highly generic—we do so by using a very
                    broad family
                    ϕ(x;
                    θ)."

                    "Human practitioners can encode their
                    knowledge to help generalization by designing families
                    ϕ(x;
                    θ) that
                    they expect will perform well."

                    --

                    "Feedforward networks are the application of this
                    principle to learning deterministic mappings from x to y that lack feedback
                    connections"

                    --

                    "First, training a feedforward network requires making many of the
                    same design decisions as are necessary for a linear model: choosing the
                    optimizer, the cost function, and the form of the output units. "

                    "We review these
                    basics of gradient-based learning, then proceed to confront some of the design
                    decisions that are unique to feedforward networks."

                    "Feedforward networks have
                    introduced the concept of a hidden layer, and this requires us to choose the
                    activation functions that will be used to compute the hidden layer values."

                    "We
                    must also design the architecture of the network, including how many layers the
                    network should contain, how these layers should be connected to each other,
                    and how many units should be in each layer."

                    "Learning in deep neural networks
                    requires computing the gradients of complicated functions"

                    "We present the
                    back-propagation algorithm and its modern generalizations, which can be used
                    to efficiently compute these gradients"

                    ----

                    "Now we must choose the form of our model, f(x;
                    θ). Suppose that we
                    choose a linear model, with
                    θ consisting of w and b."

                    "We can minimize J(
                    θ) in closed form with respect to w and b using the normal
                    equations."

                    Here (pg 224) they talk about a function f, s.t. f(x; w, b) = (x^T)w + b, which are the weights and biases associated with a neuron. And so, each neuron is structured this way to be the simplest linear model with parameters: weights (w) and biases(b). The "knobs" that can be changed are `w` and `b` which serve different purposes in the linear model, and where the model can't be made simpler and still be a "fully configurable" linear model.

                    --

                    "We use that strategy here, by defining h = g(W⊤x + c), where W provides the
                    weights of a linear transformation and c the biases. Previously, to describe a
                    linear regression model, we used a vector of weights and a scalar bias parameter
                    to describe an affine transformation from an input vector to an output scalar.
                    Now, we describe an affine transformation from a vector x to a vector h, so an
                    entire vector of bias parameters is needed."

                    "e activation function g is typically
                    chosen to be a function that is applied element-wise, with hi = g(x⊤W:,i + ci)"

                    "In modern neural networks, the default recommendation is to use the rectified
                    linear unit, or ReLU (Jarrett et al., 2009; Nair and Hinton, 2010; Glorot et al.,
                    2011a), defined by the activation function g(z) = max{0, z} ..."

                    and then the activation function is the bit that takes the linear model of the neuron as input and outputs non-linearity. Or the activation function introduces non-linearity to the linear model of the neuron as described by `f(x; w, b) = (x^T)w + b`.

                    --

                    "Much as a Turing
                    machine’s memory needs only to be able to store 0 or 1 states, we can build a
                    universal function approximator from rectified linear functions."

                    --

                    and stopped at pg 228, as then it starts talking about how to make the neural network function, and we want to just describe the smallest bit for now.
                DONE
                    modern logical neurons are "evolved" from earlier more complex representations, more closely related to biological neurons
                    and modern (artificial) neurons are seemingly the simplest logical constructs that can be used to construct a universal function approximater
                    the simplest neural network that we're going to look at is the "Deep feedforward network"
                    where:
                        ```
                        The goal of a feedforward network is to approximate some function f*.
                        For example, for a classifier, y = f*(x) maps an input x to a category y.
                        A feedforward network defines a mapping y = f(x; θ) and learns the value of the parameters θ
                        that result in the best function approximation.
                        ```
                    Where such a network is composed of:
                        input layer
                        hidden layers
                        output layer
                    Where each layer is a set of neurons that are densly connected with the next.

                    "It is best to think of feedforward networks as
                    function approximation machines that are designed to achieve statistical
                    generalization, occasionally drawing some insights from what we know about
                    the brain, rather than as models of brain function."

                    "To extend linear models to represent nonlinear functions of x, we can apply the linear model not to x itself but to a transformed input ϕ(x), where ϕ is a nonlinear transformation."

                    " ... training a feedforward network requires making many of the
                    same design decisions as are necessary for a linear model: choosing the
                    optimizer, the cost function, and the form of the output units. "

                    "Feedforward networks have introduced the concept of a hidden layer, and this requires us to choose the activation functions that will be used to compute the hidden layer values."

                    And so each neuron is structured as a linear model (f(x; w, b) = (x^T)w + b; where `w` is a vector of weights and `b` is a vector of biases), which acts as input to a non-linear activation function `g`. Which then fulfills the "extend linear models to represent nonlinear functions", via "apply the linear model not to x itself but to a transformed input ϕ(x), where ϕ is a nonlinear transformation". Where the linear model is the neuron and the activation function is the "nonlinear transformation".

                    They recommend using "rectified linear unit, or ReLU (Jarrett et al., 2009; Nair and Hinton, 2010; Glorot et al., 2011a), defined by the activation function g(z) = max{0, z}" as the activation function.

                    And "Much as a Turing machine’s memory needs only to be able to store 0 or 1 states, we can build a universal function approximator from rectified linear functions."
            DONE

            then with the theory out of the way, we can move on to the mechanics.

            --

            Artificial neuron
            https://en.wikipedia.org/wiki/Artificial_neuron
                    "An artificial neuron is a mathematical function conceived as a model of biological neurons in a neural network. Artificial neurons are the elementary units of artificial neural networks."

                    "The artificial neuron is a function that receives one or more inputs, applies weights to these inputs, and sums them to produce an output. "

                    "Usually, each input is separately weighted, and the sum is often added to a term known as a bias (loosely corresponding to the threshold potential), before being passed through a non-linear function known as an activation function or transfer function ... "

                    "The transfer functions usually have a sigmoid shape, but they may also take the form of other non-linear functions, piecewise linear functions, or step functions. They are also often monotonically increasing, continuous, differentiable and bounded."

                    For a given artificial neuron k, let there be m + 1 inputs with signals x0 through xm and weights wk0 through wkm. Usually, the x0 input is assigned the value +1, which makes it a bias input with wk0 = bk. This leaves only m actual inputs to the neuron: from x1 to xm.

                    The output of the kth neuron is:

                        y k = φ ( ∑ j = 0 m w k j x j ) {\displaystyle y_{k}=\varphi \left(\sum _{j=0}^{m}w_{kj}x_{j}\right)}

                    Where φ {\displaystyle \varphi } (phi) is the transfer function (commonly a threshold function).

                    --

                    "Any finite state machine can be simulated by a MCP neural network.[4] Furnished with an infinite tape, MCP neural networks can simulate any Turing machine."

                    --

                    pseudo code
                        see:
                        https://en.wikipedia.org/wiki/Artificial_neuron#Pseudocode_algorithm
        DONE
            using Poetry for Python package management
            installed scoop to install Windows packages
            using Windows Terminal for a terminal app
            using numpy and pytest for development during this step
            theory needed for the "Neuron" class
                And so each neuron is structured as a linear model (f(x; w, b) = (x^T)w + b; where `w` is a vector of weights and `b` is a vector of biases), which acts as input to a non-linear activation function `g`. Which then fulfills the "extend linear models to represent nonlinear functions", via "apply the linear model not to x itself but to a transformed input ϕ(x), where ϕ is a nonlinear transformation". Where the linear model is the neuron and the activation function is the "nonlinear transformation".

        --

        TODO, 1, Initialize the Network
            see:
            https://github.com/pjmattingly/1-Basic-Neural-Network-Implementation/blob/main/README.md

            and:
            https://github.com/pjmattingly/1-Basic-Neural-Network-Implementation/blob/main/1-Initialize-the-Network/Code_Structure.md

            and:
            https://github.com/pjmattingly/1-Basic-Neural-Network-Implementation/blob/main/1-Initialize-the-Network/1_initialize_the_network/Neuron.py

            --

            then type checking, how does modern Python do it?
            DONE
                annotations
                    see:
                    https://realpython.com/python-type-checking/

                and:
                    https://docs.python.org/3/library/typing.html
            
            hmm but that doesn't throw a type error when doing something like:
                `Neuron("something")`
            
            rather they're type "hints" and for linters, not enforcement for specific types passed in
                see:
                https://stackoverflow.com/questions/67412233/python-type-hinting-not-generating-error-for-wrong-type-when-running-the-code

            and so when doing exceptions for bad input, we have to check it manually
                see:
                https://realpython.com/python-type-checking/#dynamic-typing

            --

            [07.03.24]

            --

            setting up first tests for Neuron
                see:
                https://docs.pytest.org/en/8.2.x/getting-started.html#getstarted

            to get import working had to change the name of the directory containing Neuron
                Poetry automatically made: "1_initialize_the_network" instead of something that could be imported
            
            --

            take a closer look at modern coding practices, should I be making better use of autocomplete or AI?
            what's the standard tool chain for developing in Python?
                A modern toolchain for Python development typically includes tools for package management, environment management, code editing, testing, code quality, version control, and continuous integration/continuous deployment (CI/CD). Here’s a comprehensive setup:

                ### 1. **Package and Environment Management: Poetry**
                - **Description:** Poetry simplifies dependency management and project setup.
                - **Features:**
                - Manages dependencies and virtual environments.
                - Automatically resolves and installs dependencies.
                - Uses `pyproject.toml` for project configuration.
                - **Usage:**
                ```bash
                # Install Poetry
                pip install poetry

                # Initialize a new project
                poetry init

                # Add dependencies
                poetry add numpy pytest

                # Install dependencies
                poetry install

                # Activate the virtual environment
                poetry shell
                ```

                ### 2. **Code Editor/IDE: Visual Studio Code (VS Code)**
                - **Description:** A powerful, lightweight code editor with numerous extensions.
                - **Features:**
                - Integrated terminal and Git support.
                - Extensions for Python (e.g., Python extension by Microsoft).
                - Debugging support, linting, IntelliSense.
                - **Extensions:**
                - Python (by Microsoft)
                - Pylance (for type checking and language features)
                - GitLens (for enhanced Git capabilities)
                - Prettier (for code formatting)

                ### 3. **Testing: pytest**
                - **Description:** A flexible and powerful testing framework.
                - **Features:**
                - Simple syntax for writing tests.
                - Extensive plugin support.
                - Supports fixtures, parameterized tests, and more.
                - **Usage:**
                ```bash
                poetry add --dev pytest

                # Run tests
                pytest
                ```

                ### 4. **Code Quality: flake8, black, isort**
                - **flake8:** For linting and style guide enforcement.
                ```bash
                poetry add --dev flake8
                # Run flake8
                flake8 your_project/
                ```
                - **black:** For automatic code formatting.
                ```bash
                poetry add --dev black
                # Format code
                black your_project/
                ```
                - **isort:** For sorting imports.
                ```bash
                poetry add --dev isort
                # Sort imports
                isort your_project/
                ```

                ### 5. **Type Checking: mypy**
                - **Description:** Static type checker for Python.
                - **Usage:**
                ```bash
                poetry add --dev mypy
                # Run mypy
                mypy your_project/
                ```

                ### 6. **Version Control: Git**
                - **Description:** Distributed version control system.
                - **Usage:**
                ```bash
                # Initialize a new Git repository
                git init

                # Stage and commit changes
                git add .
                git commit -m "Initial commit"

                # Set up a remote repository (e.g., GitHub)
                git remote add origin https://github.com/yourusername/yourrepository.git
                git push -u origin master
                ```

                ### 7. **Continuous Integration/Continuous Deployment (CI/CD): GitHub Actions**
                - **Description:** Automate workflows for building, testing, and deploying code.
                - **Usage:**
                - Create a `.github/workflows` directory in your repository.
                - Add a workflow file (e.g., `ci.yml`) for setting up CI/CD pipelines.

                ```yaml
                name: CI

                on:
                    push:
                    branches: [ master ]
                    pull_request:
                    branches: [ master ]

                jobs:
                    build:
                    runs-on: ubuntu-latest

                    steps:
                    - uses: actions/checkout@v2
                    - name: Set up Python
                        uses: actions/setup-python@v2
                        with:
                        python-version: '3.8'
                    - name: Install dependencies
                        run: |
                        pip install poetry
                        poetry install
                    - name: Run tests
                        run: |
                        poetry run pytest
                    - name: Lint with flake8
                        run: |
                        poetry run flake8 your_project/
                    - name: Format with black
                        run: |
                        poetry run black --check your_project/
                    - name: Sort imports with isort
                        run: |
                        poetry run isort --check-only your_project/
                ```

                ### 8. **Documentation: Sphinx**
                - **Description:** Documentation generator for Python projects.
                - **Usage:**
                ```bash
                poetry add --dev sphinx
                # Initialize Sphinx
                sphinx-quickstart docs
                ```

                ### Summary

                By using this modern toolchain, you can ensure that your Python development environment is robust, efficient, and follows best practices. Here's a quick summary:

                - **Package Management:** Poetry
                - **Code Editor/IDE:** Visual Studio Code
                - **Testing:** pytest
                - **Code Quality:** flake8, black, isort
                - **Type Checking:** mypy
                - **Version Control:** Git
                - **CI/CD:** GitHub Actions
                - **Documentation:** Sphinx

                This setup will help you manage dependencies, maintain code quality, automate testing and deployment, and create comprehensive documentation for your neural network project.
            DONE
                pretty much what I have now, but things like GitLens, code quality tools, and CI/CD seem like overkill for this project

            --

            ChatGPT will do doctstrings on code review =D

            --

            adding relu as the default activation function
                see:
                https://en.wikipedia.org/wiki/Rectifier_(neural_networks)
                https://docs.python.org/3/library/functions.html#max

            --

            [07.06.24]

            --

            code review with ChatGPT for relu and forward_pass
                ChatGPT came up with this for checking if the iterable passed to forward_pass was all numeric or not.
                    see:
                    https://numpy.org/doc/stable/reference/generated/numpy.issubdtype.html
                While stackoverflow took this approach.
                    see:
                    https://stackoverflow.com/questions/37996471/element-wise-test-of-numpy-array-is-numeric
                    and:
                    https://stackoverflow.com/questions/1247486/list-comprehension-vs-map
                    and:
                    https://stackoverflow.com/questions/911871/detect-if-a-numpy-array-contains-at-least-one-non-numeric-value
            DONE

            testing for Neuron.forward_pass
            DONE

            --

            [07.08.24]

            --

            testing for `derivative_of_activation_function`

            code review for `derivative_of_activation_function` done previously.

            --

            Then onto the Layer class, a collection of Neurons

            Then the first issue, we're assuming densly connected layers, where (for hidden and output layers) the previous layers' neuron's connect to each neuron in a given Layer, and so we need two parameters for the Layer
                1) The size (in Neurons) of the Layer
                2) The number of inputs to the Layer
            Then for inputs we can just pass in numbers to avoid having to worry about passing in objects, which will be helpful for the input-layer that doesn't get its values from Neuron's

            --

            [07.09.24]

            --

            resolving `#TODO, change input checking here to match approach in Layer` in Neuron.forward_pass()

            --

            [07.11.24]

            --

            testing for Network.__init__
            DONE

            --

            implementing Network.forward_pass
                should negative inputs be allowed?
                    see:
                    https://www.researchgate.net/post/What-is-the-reason-of-choosing-negative-initial-conditions-in-Neural-network-system
                DONE
                    yes, standard practice to pre-process data to have "zero mean and unit variance"
                        see:
                        Bishop, C. M., & Nasrabadi, N. M. (2006). Pattern recognition and machine learning. New York: Springer.
                        pg. 567

                but then this implies that the weights and biases might be negative as well
                    see:
                    https://www.researchgate.net/post/What-is-the-reason-of-choosing-negative-initial-conditions-in-Neural-network-system

                so, should Neuron be changed to randomly initiailize to N(0, 1)?
                    see:
                    https://stackoverflow.com/questions/78704896/how-weight-vector-behave-when-we-initialize-the-weight-to-0-in-case-of-perceptro
                    https://stackoverflow.com/questions/44883861/initial-bias-values-for-a-neural-network
                DONE
                    yes
                        see:
                        https://www.coursera.org/lecture/neural-networks-deep-learning/random-initialization-XtFPI

                        and:
                        https://numpy.org/doc/stable/reference/random/generated/numpy.random.randn.html

                And checking Neuron.__init__ it looks like I already have it that way, oops

                But then this, says that the biases can be initialized to zero, and is desirable, and so why is that?
                    see:
                    https://www.coursera.org/lecture/neural-networks-deep-learning/random-initialization-XtFPI

                    --

                    see:
                    https://stackoverflow.com/questions/44883861/initial-bias-values-for-a-neural-network
                    https://forums.fast.ai/t/why-is-it-okay-to-set-the-bias-vector-up-with-zeros-and-not-the-weight-matrices/80759/2
                DONE
                    the consensus seems to be that the weights are the important bit for "breaking symmetry", and so random initialization of the biases can be neglected as they don't have a (significant) impact on "breaking symmetry"
                        see:
                        https://cs231n.github.io/neural-networks-2/
            DONE

            --

            [07.13.24]

            --

            testing Network.forward_pass, and Layer.forward_pass (oops)
            DONE

            --

            then, the coding plan calls for a "Training" method, but doesn't provide detail on how to do that.
                checking wih ChatGPT, and getting a more in-depth answer.
                    see:
                    https://chatgpt.com/c/5380ffd7-2b2c-4244-82f1-2ee744e67254

                    --

                    ### Implementation Details for the "Training" Method in the `Network` Class

                    The "Training" method in a neural network class is responsible for adjusting the network's weights and biases to minimize the difference between the predicted outputs and the actual target values. This process typically involves several key steps, which can be broken down as follows:

                    1. **Initialization:**
                    - **Set Hyperparameters:** Define the learning rate, number of epochs, batch size, and any other hyperparameters required for training.
                    - **Initialize Parameters:** Ensure weights and biases are initialized, usually done in the network or layer initialization.

                    2. **Forward Pass:**
                    - For each training example (or batch of examples), perform a forward pass to calculate the predicted outputs using the current weights and biases.
                    - **Input Data:** Pass the input features through the network layers sequentially, applying activation functions at each layer to produce the output.

                    3. **Loss Calculation:**
                    - **Compute Loss:** Calculate the loss (or error) between the predicted outputs and the actual target values. Common loss functions include Mean Squared Error (MSE) for regression tasks and Cross-Entropy Loss for classification tasks.
                    - **Loss Function:** Use the chosen loss function to measure how far the predicted values are from the actual values.

                    4. **Backward Pass (Backpropagation):**
                    - **Calculate Gradients:** Compute the gradients of the loss function with respect to each weight and bias in the network. This involves applying the chain rule to propagate the error backward through the network.
                    - **Gradient Calculation:** For each layer, calculate the gradient of the loss with respect to the layer's weights and biases.

                    5. **Parameter Update:**
                    - **Update Weights and Biases:** Adjust the weights and biases using the calculated gradients. This is typically done using an optimization algorithm such as Stochastic Gradient Descent (SGD), Adam, or RMSprop.
                    - **Learning Rate:** Apply the learning rate to scale the gradient updates, ensuring they are neither too large nor too small.

                    6. **Epoch Loop:**
                    - **Repeat for Each Epoch:** Iterate through the entire dataset multiple times (epochs). In each epoch, iterate through all training examples (or batches) to perform the forward pass, loss calculation, backward pass, and parameter update.

                    7. **Batch Processing (Optional):**
                    - **Mini-Batch Gradient Descent:** Instead of using the entire dataset at once, split the data into mini-batches and update parameters for each mini-batch. This can improve the efficiency and stability of training.

                    8. **Evaluation (Optional):**
                    - **Validation Set:** Use a separate validation set to evaluate the network's performance after each epoch. This helps in monitoring for overfitting and adjusting hyperparameters.
                    - **Metrics Calculation:** Calculate metrics such as accuracy, precision, recall, etc., to assess the network's performance on the validation set.

                    9. **Stopping Criteria:**
                    - **Early Stopping (Optional):** Implement early stopping based on validation performance to prevent overfitting.
                    - **Number of Epochs:** Stop training after a predefined number of epochs or when the loss converges.

                    10. **Logging and Monitoring:**
                        - **Track Progress:** Log training metrics such as loss and accuracy after each epoch to monitor the network's learning progress.
                        - **Visualization:** Optionally visualize the training progress using tools like TensorBoard or Matplotlib.

                    ### Summary

                    The training method in a neural network class involves the following key steps: initializing hyperparameters, performing forward passes to compute predictions, calculating the loss, conducting backward passes to compute gradients, updating parameters, and repeating these steps across multiple epochs. Additionally, optional steps like mini-batch processing, validation, early stopping, and logging can be included to enhance the training process.

                then, checking `Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT press.` to verify
                    352
                        "It is also crucial that the minibatches be selected randomly. Computing an
                        unbiased estimate of the expected gradient from a set of samples requires that those samples be independent"

                        "We also wish for two subsequent gradient
                        estimates to be independent from each other, so two subsequent minibatches
                        of examples should also be independent from each other."

                        "Fortunately, in practice it is usually
                        sufficient to shuffle the order of the dataset once and then store it in shuffled
                        fashion."

                        "This deviation from true random selection does not seem to have a
                        significant detrimental effect"

                        --

                        "Many optimization problems in machine learning decompose over
                        examples well enough that we can compute entire separate updates over
                        different examples in parallel"

                        " In other words, we can compute the update that
                        minimizes J(X) for one minibatch of examples X at the same time that we
                        compute the update for several other minibatches. Such asynchronous parallel
                        distributed approaches are discussed further in section 12.1.3."

                        353
                            "Hence, we can obtain an unbiased estimator of the exact gradient of the
                            generalization error by sampling a minibatch of examples {x(1), … x(m)} with
                            corresponding targets y(i) from the data-generating distribution pdata, then
                            computing the gradient of the loss with respect to the parameters for that
                            minibatch"

                        354
                            "Of course, this interpretation applies only when examples are not reused"

                            "Nonetheless, it is usually best to make several passes through the training set,
                            unless the training set is extremely large."

                        --

                        "Traditionally, machine
                        learning has avoided the difficulty of general optimization by carefully
                        designing the objective function and constraints to ensure that the
                        optimization problem is convex"

                        "When training neural networks, we must
                        confront the general nonconvex case"

                        356
                            "With nonconvex functions, such as neural nets, it is possible to have many
                            local minima. "

                            "Neural networks and any models with multiple equivalently parametrized
                            latent variables all have multiple local minima because of the **model
                            identifiability problem**."

                            "A model is said to be identifiable if a sufficiently large
                            training set can rule out all but one setting of the model’s parameters."

                            "Models
                            with latent variables are often not identifiable because we can obtain equivalent
                            models by exchanging latent variables with each other"

                        --

                        (bolded term)
                            "**weight space symmetry**"

                        --

                        "These model identifiability issues mean that a neural network cost function
                        can have an extremely large or even uncountably infinite amount of local
                        minima."

                        "However, all these local minima arising from nonidentifiability are
                        equivalent to each other in cost function value."

                        --

                        [07.13.24]

                        --

                        "For many high-dimensional nonconvex functions, local minima (and maxima)
                        are in fact rare compared to another kind of point with zero gradient: a saddle
                        point."

                        "We can think of
                        a saddle point as being a local minimum along one cross-section of the cost
                        function and a local maximum along another cross-section. "

                        --

                        "Many classes of random functions exhibit the following behavior: in low-
                        dimensional spaces, local minima are common."

                        "In higher-dimensional spaces,
                        local minima are rare, and saddle points are more common"

                        "For a function f :
                        ℝn → ℝ of this type, the expected ratio of the number of saddle points to local
                        minima grows exponentially with n."

                        "To understand the intuition behind this
                        behavior, observe that the Hessian matrix at a local minimum has only positive
                        eigenvalues. e Hessian matrix at a saddle point has a mixture of positive and
                        negative eigenvalues. Imagine that the sign of each eigenvalue is generated by
                        flipping a coin. In a single dimension, it is easy to obtain a local minimum by
                        tossing a coin and getting heads once. In n-dimensional space, it is
                        exponentially unlikely that all n coin tosses will be heads. See Dauphin et al.
                        (2014) for a review of the relevant theoretical work."

                        --

                        discussion of the "vanishing and exploding gradient problem"
                            "e vanishing and exploding gradient problem refers to the fact
                            that gradients through such a graph are also scaled according to diag(
                            λ)t.
                            Vanishing gradients make it difficult to know which direction the parameters
                            should move to improve the cost function, while exploding gradients can make
                            learning unstable. e cliff structures described earlier that motivate gradient
                            clipping are an example of the exploding gradient phenomenon."

                        --

                        "Many of the problems we have discussed so far correspond to properties of the
                        loss function at a single point—it can be difficult to make a single step if J(
                        θ)
                        is poorly conditioned at the current point
                        θ, or if
                        θ lies on a cliff, or if
                        θ is a
                        saddle point hiding the opportunity to make progress downhill from the
                        gradient."

                        --

                        "Stochastic gradient descent (SGD) and its variants are probably the most used
                        optimization algorithms for machine learning in general and for deep learning
                        in particular. "

                        "A crucial parameter for the SGD algorithm is the learning rate. Previously,
                        we have described SGD as using a fixed learning rate ϵ. In practice, it is
                        necessary to gradually decrease the learning rate over time, so we now denote
                        the learning rate at iteration k as ϵk."

                        --

                        A sketch of SGD
                            Algorithm 8.1 Stochastic gradient descent (SGD) update at training iteration
                            k
                            
                            Require: Learning rate schedule ϵ1, ϵ2, …
                            Require: Initial parameter
                            θ
                            k ← 1
                            while stopping criterion not met do
                                Sample a minibatch of m examples from the training set {x(1), … , x(m)}
                                with corresponding targets y(i).
                                Compute gradient estimate: g_hat <- +(1/m)*(gradient w.r.t theta)(sum over the loss function (L) with parameters f(x[i]; theta); y[i])
                                Apply update:
                                θ ← θ − ϵkĝ.
                                k ← k + 1
                            end while

                            (a note on "Compute gradient estimate", that it's computing the average of the loss function multiplied by the gradient w.r.t to the parameter theta)

                        Then a discussion of how to decay the learning rate ϵ:
                            ```
                            In practice, it is common to decay the learning rate linearly until iteration τ:
                                ϵk = (1 - :alpha:)ϵ0 + :alpha:ϵ_τ
                            
                            with :alpha: = k / τ.
                            
                            After iteration τ, it is common to leave ϵ constant.
                            ```

                            (with k being the kth step in the SGD algorithm, as above)

                        "The learning rate may be chosen by trial and error, but it is usually best to
                        choose it by monitoring learning curves that plot the objective function as a
                        function of time."

                        --

                        "When using the linear
                        schedule, the parameters to choose are ϵ0, ϵ
                        τ, and
                        τ. Usually
                        τ may be set to
                        the number of iterations required to make a few hundred passes through the
                        training set."

                        "Usually ϵ
                        τ should be set to roughly 1 percent the value of ϵ0."

                        "e
                        main question is how to set ϵ0. If it is too large, the learning curve will show
                        violent oscillations, with the cost function often increasing significantly. Gentle
                        oscillations are fine, especially if training with a stochastic cost function, such
                        as the cost function arising from the use of dropout. If the learning rate is too
                        low, learning proceeds slowly, and if the initial learning rate is too low, learning
                        may become stuck with a high cost value"

                        " Typically, the optimal initial learning
                        rate, in terms of total training time and the final cost value, is higher than the
                        learning rate that yields the best performance after the first 100 iterations or so.
                        erefore, it is usually best to monitor the first several iterations and use a
                        learning rate that is higher than the best-performing learning rate at this time,
                        but not so high that it causes severe instability."

                        --

                        "To study the convergence rate of an optimization algorithm it is common
                        to measure the excess error J(
                        θ) − min
                        θJ(
                        θ), which is the amount by which
                        the current cost function exceeds the minimum possible cost"

                        --

                        "While stochastic gradient descent remains a popular optimization strategy,
                        learning with it can sometimes be slow. e method of momentum (Polyak,
                        1964) is designed to accelerate learning, especially in the face of high
                        curvature, small but consistent gradients, or noisy gradients. e momentum
                        algorithm accumulates an exponentially decaying moving average of past
                        gradients and continues to move in their direction."

                        --

                        Then a discussion of the "Stochastic gradient descent (SGD) with momentum" algorithm on pg 327 - 373

                        --

                        "8.3.3 Nesterov Momentum" starting on pg. 375

                        --

                        "Training algorithms for deep learning models are usually
                        iterative and thus require the user to specify some initial point from which to
                        begin the iterations."

                        "Moreover, training deep models is a sufficiently difficult
                        task that most algorithms are strongly affected by the choice of initialization."

                        "e initial point can determine whether the algorithm converges at all, with
                        some initial points being so unstable that the algorithm encounters numerical
                        difficulties and fails altogether"

                        --

                        An extended discussion on why the initial weights are initialized randomly, and addressing the "symmetry breaking problem"
                            "Perhaps the only property known with complete certainty is that the initial
                            parameters need to “break symmetry” between different units"

                            " If two hidden
                            units with the same activation function are connected to the same inputs, then
                            these units must have different initial parameters"

                            "If they have the same initial
                            parameters, then a deterministic learning algorithm applied to a deterministic
                            cost and model will constantly update both of these units in the same way."

                            "Even if the model or training algorithm is capable of using stochasticity to
                            compute different updates for different units (for example, if one trains with
                            dropout), it is usually best to initialize each unit to compute a different
                            function from all the other units."

                            "is may help to make sure that no input
                            patterns are lost in the null space of forward propagation and that no gradient
                            patterns are lost in the null space of back-propagation."

                            "e goal of having each
                            unit compute a different function motivates random initialization of the
                            parameters"

                            "Random initialization from a high-entropy
                            distribution over a high-dimensional space is computationally cheaper and
                            unlikely to assign any units to compute the same function as each other."

                            "We almost always initialize all the weights in the model to values drawn
                            randomly from a Gaussian or uniform distribution."

                            "Larger initial weights will yield a stronger symmetry-breaking effect,
                            helping to avoid redundant units."

                            "Initial weights that are too large may, however, result in exploding values
                            during forward propagation or back-propagation."

                            --

                            "e optimization perspective
                            suggests that the weights should be large enough to propagate information
                            successfully, but some regularization concerns encourage making them smaller"

                        --

                        Then a discussion about why the biases are typically initialized to zero
                            "e approach for setting the biases must be coordinated with the approach
                            for setting the weights. Setting the biases to zero is compatible with most
                            weight initialization schemes."
                DONE
                    [07.25.24]

                    When using a mini-batch approach, select the batches randomly.
                        "Computing an unbiased estimate of the expected gradient from a set of samples requires that those samples be independent"
                    And instead of randomly sampling the set of mini-batches that can be made of the data-set, a shuffle of the data-set and iterating through it linearly is commonly sufficient.
                        "Fortunately, in practice it is usually sufficient to shuffle the order of the dataset once and then store it in shuffled fashion."
                    It's possible to do _some_ resolutions of optimization problems in parallel through a Neural Network.
                        "Many optimization problems in machine learning decompose over
                        examples well enough that we can compute entire separate updates over
                        different examples in parallel"
                    "Nonetheless, it is usually best to make several passes through the training set, unless the training set is extremely large."
                    As the dimension of the inputs gets larger, the more common saddle-points become in the function formed via the neural network.
                        "For many high-dimensional nonconvex functions, local minima (and maxima) are in fact rare compared to another kind of point with zero gradient: a saddle point."
                    Stochastic Gradient Descent
                        "Stochastic gradient descent (SGD) and its variants are probably the most used optimization algorithms for machine learning in general and for deep learning in particular."

                        A parameter for SGD is the learning rate (ϵ), and in practice it decays over time while running and SGD operation.

                        A sketch of SGD
                            Algorithm 8.1 Stochastic gradient descent (SGD) update at training iteration
                            k
                            
                            Require: Learning rate schedule ϵ1, ϵ2, …
                            Require: Initial parameter
                            θ
                            k ← 1
                            while stopping criterion not met do
                                Sample a minibatch of m examples from the training set {x(1), … , x(m)}
                                with corresponding targets y(i).
                                Compute gradient estimate: g_hat <- +(1/m)*(gradient w.r.t theta)(sum over the loss function (L) with parameters f(x[i]; theta); y[i])
                                Apply update:
                                θ ← θ − ϵkĝ.
                                k ← k + 1
                            end while

                            (a note on "Compute gradient estimate", that it's computing the average of the loss function multiplied by the gradient w.r.t to the parameter theta)

                        Then a discussion of how to decay the learning rate ϵ:
                            ```
                            In practice, it is common to decay the learning rate linearly until iteration τ:
                                ϵk = (1 - :alpha:)ϵ0 + :alpha:ϵ_τ
                            
                            with :alpha: = k / τ.
                            
                            After iteration τ, it is common to leave ϵ constant.
                            ```

                            (with k being the kth step in the SGD algorithm, as above)

                        Various tips on setting parameters for SGD, or how to measure performance of SGD to infer good values of said parameters
                            "When using the linear schedule, the parameters to choose are ϵ0, ϵτ, and τ. Usually τ may be set to the number of iterations required to make a few hundred passes through the training set."

                            "Usually ϵτ should be set to roughly 1 percent the value of ϵ0."

                            " Typically, the optimal initial learning rate, in terms of total training time and the final cost value, is higher than the learning rate that yields the best performance after the first 100 iterations or so. Therefore, it is usually best to monitor the first several iterations and use a learning rate that is higher than the best-performing learning rate at this time, but not so high that it causes severe instability."
                    A discussion of the "Stochastic gradient descent (SGD) with momentum" algorithm on pg 327 - 373.
                    The "symmetry breaking problem" centers around the desire to avoid "that no input patterns are lost in the null space of forward propagation and that no gradient patterns are lost in the null space of back-propagation". Then also, it's helpful to avoid having individual units of a neural network compute the same or similar function. And so to avoid such issues, the standard remedy for this issues is random initialization of the weights.
            DONE
                the ChatGPT sketch of the training algorithm is essentially correct.

            --

            Pseudo-code the training method.
                def training(self, data, learning_rate=None, epochs=None):
                    #doing a simple training algorithm
                    #no batching, using the entire training set for training
                    #no splitting data into "Training" and "Validation" sets
                    #no early stopping criteria

                    for _ in range(epochs):
                        data = random.shuffle(data)

                        outputs = [self.forward_pass(x) for x in data[x]]

                        _log_accuracy(results, data[y])

                        losses = loss_calc(results, data[y])

                        #logging loss
                        print(losses)

                        #how to do the backward pass? What parameters does it need?
                        new_weights_and_biases = self._backward_pass(losses) #PLACEHOLDER

                        for i, update in enumerate(new_weights_and_biases):
                            #TODO, how to update the new weights and biases given the current 
                            # learning rate during the i_th epoch?
                            new_weight = update[weight]*learning_rate #PLACEHOLDER
                            new_bias = update[bias]*learning_rate #PLACEHOLDER

                            self.update_weight(i, new_weight)
                            self.update_bias(i, new_bias)

            And so first, need to check the data
                should be a set of records of the form: {x: inputs; y: ouputs}
                and only accepting numerical values for `inputs` and outputs`

            --

            [07.16.24]

            --

            implementing Network._check_data
                chatgpt input on sanity checks for data
                    ```
                    When performing sanity checks on data that will be used to train a neural network, it is essential to ensure that the data is clean, well-formatted, and suitable for training. Here are several types of sanity checks you should consider:

                    ### 1. **Basic Data Integrity Checks:**
                    - **Non-Empty Data:** Ensure that the dataset is not empty.
                    - **Correct Data Types:** Verify that all features and labels are of the expected data types (e.g., numerical, categorical).
                    - **No Missing Values:** Check for and handle any missing values (e.g., NaNs or nulls).

                    ### 2. **Shape and Dimension Checks:**
                    - **Consistent Dimensions:** Ensure that all input features have consistent dimensions across samples.
                    - **Label Alignment:** Verify that the number of labels matches the number of samples.

                    ### 3. **Range and Value Checks:**
                    - **Valid Range:** Check that numerical features fall within expected ranges (e.g., no negative values for features that should be non-negative).
                    - **No Outliers:** Detect and handle outliers that may adversely affect model training.

                    ### 4. **Distribution Checks:**
                    - **Feature Distribution:** Examine the distribution of each feature to ensure they are as expected (e.g., normally distributed, uniformly distributed).
                    - **Class Balance:** Check for class imbalance in classification tasks and consider techniques to handle it if necessary (e.g., oversampling, undersampling).

                    ### 5. **Uniqueness and Redundancy Checks:**
                    - **Duplicate Samples:** Identify and remove duplicate samples to avoid bias.
                    - **Unique Identifiers:** Ensure any identifiers or indexes are unique and correctly assigned.

                    ### 6. **Correlation and Multicollinearity:**
                    - **Feature Correlation:** Check for high correlation between features and address multicollinearity, which can affect model performance.
                    - **Redundant Features:** Identify and consider removing redundant features that do not add significant value.

                    ### 7. **Categorical Data Checks:**
                    - **Consistent Categories:** Verify that categorical features have consistent categories across the dataset.
                    - **Encoding:** Ensure that categorical data is properly encoded (e.g., one-hot encoding, label encoding).

                    ### 8. **Time Series Specific Checks:**
                    - **Temporal Order:** For time series data, ensure that the data is sorted in temporal order.
                    - **Missing Time Stamps:** Check for and handle any missing timestamps or irregular time intervals.

                    ### 9. **Data Leakage Prevention:**
                    - **Train-Test Split:** Ensure that the training data and test data are correctly split and that no test data is included in the training set.
                    - **Feature Leakage:** Verify that no future information (data that would not be available at training time) is included in the features.

                    ### 10. **Target Variable Checks:**
                    - **Valid Labels:** Ensure that the target variable (labels) contains valid values and no anomalies.
                    - **Consistent Encoding:** For classification tasks, verify that labels are consistently encoded.

                    ### 11. **Format and Consistency:**
                    - **File Formats:** Ensure that data files are in the correct format and encoding (e.g., CSV, JSON).
                    - **Consistent Units:** Check that all measurements are in consistent units.

                    ### 12. **Feature Engineering Validation:**
                    - **Derived Features:** Validate that any derived features are correctly calculated and meaningful.
                    - **Feature Scaling:** Ensure that features are properly scaled or normalized if required by the model (e.g., standardization, min-max scaling).

                    ### Summary

                    Performing these sanity checks helps to ensure the quality and reliability of your training data, which is crucial for building an effective and accurate neural network model. By addressing potential issues early, you can avoid many common pitfalls that could lead to poor model performance or training instability.
                    ```

            --

            [07.17.24]

            --

            I was assuming that data-sets "x" and "y" would be lists of lists, but it should be possible for a data-set to just be single numbers:
                `Network._check_data(None, {"x": [1, 2, 3, 4], "y": [1, 2, 3, 4]})`
            which fails with:
                ```
                Traceback (most recent call last):
                File "D:\Github\1-Basic-Neural-Network-Implementation\1-Initialize-the-Network\init_the_network\Network.py", line 229, in <module>
                    Network._check_data(None, {"x": [1, 2, 3, 4], "y": [1, 2, 3, 4]})
                File "D:\Github\1-Basic-Neural-Network-Implementation\1-Initialize-the-Network\init_the_network\Network.py", line 202, in _check_data
                    x_lengths = {len(x_sample) for x_sample in x_data}
                                ^^^^^^^^^^^^^
                ```
            and so need handling for that

            then checking for all numeric or all iterable data-sets, and throwing errors if there's a mix of types
            but this makes the function way too long, and so needs some refactor into many small functions for easier readability

            --

            check that a list of empty lists is checked for and throws an error:
                `Network._check_data(None, {"x": [[], [], [], []], "y": [[], [], [], []]})`
            to check, perhaps flatten the input and look for numbers?

            also checking for some items that are empty
                which numpy seems to catch:

                ```
                Traceback (most recent call last):
                File "D:\Github\1-Basic-Neural-Network-Implementation\1-Initialize-the-Network\init_the_network\Network.py", line 265, in <module>
                    Network._check_data(None, {"x": [[1], [2], [3], [4]], "y": [[1], [2], [3], []]})
                File "D:\Github\1-Basic-Neural-Network-Implementation\1-Initialize-the-Network\init_the_network\Network.py", line 186, in _check_data
                    na_y = np.array(y_data)
                        ^^^^^^^^^^^^^^^^
                ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.
                ```
            DONE
                though in this case the error is about mismatched dimensions, rather than noting an empty data-set item, but it doesn't seem worth it to get that specific.

            --

            [07.18.24]

            --

            refactor to make Network._check_data call several sub-methods for each of its checks, rather than one big method
            DONE

            --

            [07.19.24]

            --

            testing Network._check_data, and its subordinate methods
            DONE

            --

            [07.20.24]

            --

            code review on Network._check_data, and its subordinate methods
            DONE

            redoing docstring for Network._check_data, and adding docstrings to all subordinate methods
            DONE

            --

            adding checks for the "epochs" and "learning rate" parameters.

            --

            [07.21.24]

            --

            Network._loss_calc
                refreshing on loss
                    see:
                    https://www.datacamp.com/tutorial/loss-function-in-machine-learning

                and so we can do MSE, which means our data should be solvable as a regression problem
            DONE


            
            next,
                testing for Network._loss_calc
            then,
                first live testing
                    TODO, generate randomized data fit to a linear equation, so that it can be used for training the Network
                    since Mean Squared Error is being used for the loss function, then the problem the Network is being configured to solve should be regression
                        see:
                        https://www.datacamp.com/tutorial/loss-function-in-machine-learning
                    and
                    TODO, setup random "seed" for Neuron, Layer, and Network, so we can get reproducable results when testing
                        see:
                        https://github.com/pjmattingly/1-Basic-Neural-Network-Implementation/tree/main/1-Initialize-the-Network#practical-tips
                    and
                    do forward pass and loss calculation just to make sure everything works
                        + add testing that duplicates this process

            then,
                Network._log_accuracy ?
                    can we do something useful here with a regression problem?
            
            then,
            moving on to Network_backward_pass
                reference header "then, checking `Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT press.` to verify" for implementation details of the training method.
                And see file titled "### Implementation Details for the "Training" Method in the `Network` Class" for overview of how to implement Network.training
                And see pseudo code in Network.training method placeholder
            

----------------

TODO
    TODO, double check previous reading, do we want to vary the learning rate over multiple epochs?

    --

    TODO, for the BackProp part, see `Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT press.`
        5.3. Error Backpropagation, pg 241



----------------

NOTE
    Note, handy discussion of how to experiment with and settle on a learning rate or at least an initial learning rate
        see:
        https://ai.stackexchange.com/questions/26502/is-there-an-ideal-range-of-learning-rate-which-always-gives-a-good-result-almost

        and:
        https://stackoverflow.com/questions/42966393/is-it-good-learning-rate-for-adam-method
        (for its visualizations)
    
    --

    Note, helpful Neuron visualization diagram
        see:
        https://www.researchgate.net/figure/A-diagram-to-show-the-work-of-a-neuron-input-x-weights-w-bias-b-activation-function-f_fig1_323775654
    
    --

    Note, a project for visualizing Neural Networks
        see:
        https://github.com/HarisIqbal88/PlotNeuralNet

        also:
        https://datascience.stackexchange.com/questions/14899/how-to-draw-deep-learning-network-architecture-diagrams

    --

    Note, header "first, checking on the structure of artificial neurons; Why are they structured the way they are?" describes the motivation for and structure of the artificial neuron

    --

    Note, pg 228+ in "Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT press." provides further information on how to make the example feedforward network function
        see:
        C:\Users\peter-work\Calibre Library\Goodfellow, Ian; Bengio, Yoshua; Cou\Deep Learning (19)\Deep Learning - Goodfellow, Ian; Bengio, Yoshua.pdf

    --

    Note, chatgpt chat
        see:
        https://chatgpt.com/c/5380ffd7-2b2c-4244-82f1-2ee744e67254?model=gpt-4o

    --

    Note, roadmap for developing an LLM based chat bot.
        see:
        https://github.com/pjmattingly/1-Basic-Neural-Network-Implementation/blob/main/LLM_chatbot_Roadmap.md

        --

        Basic Neural Network Implementation

        Objective: Understand the fundamentals of neural networks.
        Project: Implement a simple feedforward neural network from scratch.
        Skills Learned: Backpropagation, gradient descent, activation functions.
        Technologies: Pure Python, NumPy.

        Using a Deep Learning Framework

        Objective: Get familiar with a popular deep learning framework.
        Project: Re-implement the basic neural network using PyTorch or TensorFlow.
        Skills Learned: Using tensors, automatic differentiation, basic model training.
        Technologies: PyTorch, TensorFlow.

        Text Data Preprocessing

        Objective: Learn how to preprocess text data for NLP tasks.
        Project: Implement text preprocessing techniques such as tokenization, stemming, lemmatization, and stop words removal.
        Skills Learned: Text normalization, handling different text formats.
        Technologies: NLTK, SpaCy.

        Word Embeddings and Text Representation

        Objective: Understand how to represent text data in a way that neural networks can process.
        Project: Implement and use word embeddings like Word2Vec or GloVe for text representation.
        Skills Learned: Embedding layers, vector space models.
        Technologies: Gensim, PyTorch, TensorFlow.

        Recurrent Neural Networks (RNNs) and LSTMs

        Objective: Learn about RNNs for handling sequential data.
        Project: Build an RNN or LSTM for a simple text generation task.
        Skills Learned: Handling sequences, managing hidden states, text generation.
        Technologies: PyTorch, TensorFlow.

        Transformer Models

        Objective: Dive into the architecture behind modern LLMs.
        Project: Implement a simple transformer model for a text-based task, such as translation or summarization.
        Skills Learned: Attention mechanisms, positional encoding, multi-head attention.
        Technologies: PyTorch, TensorFlow, Hugging Face Transformers.

        Fine-Tuning Pre-Trained Models

        Objective: Leverage pre-trained models for specific NLP tasks.
        Project: Fine-tune a pre-trained BERT or GPT model for a custom text classification task.
        Skills Learned: Transfer learning, fine-tuning, handling large-scale pre-trained models.
        Technologies: Hugging Face Transformers, PyTorch, TensorFlow.

        Building a Basic Chatbot

        Objective: Create an interactive chatbot with basic conversational capabilities.
        Project: Develop a simple rule-based chatbot to handle predefined interactions.
        Skills Learned: Basic NLP techniques, intent recognition, response generation.
        Technologies: NLTK, Rasa, Python.

        Developing a Context-Aware Chatbot

        Objective: Enhance the chatbot with context management for more natural conversations.
        Project: Implement a context-aware chatbot using an LSTM or Transformer-based model.
        Skills Learned: Context tracking, managing stateful interactions.
        Technologies: Rasa, PyTorch, TensorFlow.

        Integrating a Pre-Trained LLM into the Chatbot

        Objective: Leverage a pre-trained LLM for sophisticated responses.
        Project: Integrate GPT-3 (via OpenAI API) or another LLM into your chatbot for more advanced conversations.
        Skills Learned: API integration, managing API limitations, ensuring coherent responses.
        Technologies: OpenAI API, Hugging Face Transformers, Flask/Django for web integration.

        Polishing the User Interface

        Objective: Make the chatbot user-friendly and visually appealing.
        Project: Develop a web or mobile interface for your chatbot.
        Skills Learned: Front-end development, integrating back-end AI models with the UI.
        Technologies: React.js, Vue.js, HTML/CSS, Flask/Django, RESTful APIs.

        Deployment and Scaling

        Objective: Deploy the chatbot and ensure it can handle multiple users.
        Project: Deploy your chatbot on a cloud platform, ensure it is scalable and reliable.
        Skills Learned: Cloud deployment, containerization (Docker), orchestration (Kubernetes).
        Technologies: AWS/GCP/Azure, Docker, Kubernetes.

    --

    Note, bibliography
        Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT press.
            see:
            D:\c drive storage\Work\IT, LLM Chatbot\bib\Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT press.pdf

        Bishop, C. M., & Nasrabadi, N. M. (2006). Pattern recognition and machine learning. New York: Springer.
            see:
            Bishop, C. M., & Nasrabadi, N. M. (2006). Pattern recognition and machine learning. New York Springer.pdf

    --
        
    Note, dev dir
        see:
        D:\Github

----------------

DONE
    TODO, before development, review: "Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT press."
        see:
        C:\Users\peter-work\Calibre Library\Goodfellow, Ian; Bengio, Yoshua; Cou\Deep Learning (19)\Deep Learning - Goodfellow, Ian; Bengio, Yoshua.pdf
    DONE

    --

    TODO, take a closer look at the "symmetry breaking problem"
        " And then b, it turns out that b does not have the symmetry problem, what's called the symmetry breaking problem."
            see:
            https://www.coursera.org/lecture/neural-networks-deep-learning/random-initialization-XtFPI

        --

        prior research
            see:
            https://stackoverflow.com/questions/59638646/what-does-it-mean-to-break-symmetry-in-the-context-of-neural-network-programm
            and:
            https://stackoverflow.com/questions/20027598/why-should-weights-of-neural-networks-be-initialized-to-random-numbers
            https://ai.stackexchange.com/questions/6789/is-random-initialization-of-the-weights-the-only-choice-to-break-the-symmetry
            https://proceedings.neurips.cc/paper_files/paper/2017/file/a96b65a721e561e1e3de768ac819ffbb-Paper.pdf
    DONE
        see header "then, checking `Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT press.` to verify"

# tail